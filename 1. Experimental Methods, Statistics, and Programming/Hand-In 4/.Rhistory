metallica<-c("Lars","James","Jason","Kirk")
metalica
print(metallica)
metallica<-metallica[metallica!= "Jason"]
metallica
metallica<-c(metallica, "Rob")
metallica
friends<-c(friends, "Mille", "Nina", "Kiri", "Jacob")
friends<-c("Mille","Nina","Kiri","Jacob")
friends
friends<-c("Mille","Nina","Kiri","Jacob")
friends<-friends[]
friends<-friends[!= "Jacob"]
friends<-friends[friends!= "Jacob"]
friends
friends<-c(friends, "Jacob")
friends
metallica
metallica
friends
friends<-friends[friends != "Jacob]
"]
friends
friends<-friends[friends != "Jacob"]
friends
friends<-friends[friends!= "Jacob"]
friends
friends<-c(friends, "Jacob")
friends
metallicaNames<-c("Lars","James","Kirk","Rob")
metallicaNames
metallicaAges<-c(47, 47, 48, 46)
metallicaAges
metallica<-data.frame(Name = metallicaNames, Age = metallicaAges)
metallica
metallica$Name
metallica$Age
metallica$childAge<-c(12, 12, 4, 6)
metallica$childAge
metallica
names(metallica)
metallica$fatherhoodAge<- metallica$Age & minus metallica$childAge
metallica$fatherhoodAge<- metallica$Age & - metallica$childAge
fatherhoodAge
metallica
metallica$fatherhoodAge<- metallica$Age - metallica$childAge
metallica
metallicaNames<-c("Lars","James","Kirk","Rob")
metallicaNames
metallicaAges<-c(47, 47, 48, 46)
metallicaAges
metallica<-data.frame(Name = metallicaNames, Age = metallicaAges)
metallica$Age
metallica$childAge<-c(12, 12, 4, 6)
metallica$childAge
metallica
names(metallica)
metallica$fatherhoodAge<- metallica$Age - metallica$childAge
name<-c("Ben", "Martin", "Andy", "Paul", "Graham", "Carina", "Karina", "Doug", "Mark", "Zoe")
husband<-as.Date(c("1973-06-21", "1970-07-16", "1949-10-08", "1969-05-24"))
wife<-as.Date(c("1984-11-12", "1973-08-02", "1948-11-11", "1983-07-23"))
agegap<-husband-wife
agegap
birth_date<-as.Date(c("1977-07-03", "1969-05-24", "1973-06-21","1970-07-16", "1949-10-10", "1983-11-05", "1987-10-08", "1989-09-16","1973-05-20", "1984-11-12"))
job<-c(1,1,1,1,1,2,2,2,2,2)
job
job<-factor(job, levels = c(1:2), labels = c("Lecturer", "Student"))
job<-gl(2, 5, labels = c("Lecturer", "Student"))
levels(job)
levels(job)<-c("Medical Lecturer", "Medical Student")
friends<-c(5,2,0,4,1,10,12,15,12,17)
alcohol<-c(10,15,20,5,30,25,20,16,17,18)
income<-c(20000,40000,35000,22000,50000,5000,100,3000,10000,10)
neurotic<-c(10,17,14,13,21,7,13,9,14,13)
lecturerData<-data.frame(name,birth_date,job,friends,alcohol,income,neurotic)
lecturerData
lecturerPersonality <- lecturerData[, c("friends", "alcohol","neurotic")]
lecturerPersonality
lecturerOnly <- lecturerData[job=="Medical Lecturer",]
lecturerOnly
alcoholPersonality <- lecturerData[alcohol > 10, c("friends","alcohol", "neurotic")]
alcoholPersonality
alcoholPersonalityMatrix <- as.matrix(alcoholPersonality)
alcoholPersonalityMatrix
alcoholPersonalityMatrix <- as.matrix(lecturerData[alcohol > 10,c("friends", "alcohol", "neurotic")])
alcoholPersonalityMatrix
satisfactionData = read.delim("Honeymoon Period.dat", header = TRUE)
satisfactionData = read.delim("Honeymoon Period.dat", header = TRUE)
satisfactionData = read.delim("Honeymoon Period.dat.txt", header = TRUE)
setwd("~/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio")
#Load data
search<- read.csv("~/Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
#Load data
search<- read.csv("~Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
#Load data
search<- read.csv("Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
#Load data
search<- read.csv("/Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
'% accuracy:'
mean(search$correct_resp,na.rm = TRUE)*100
#Load data
search<- read.csv("/Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
'% accuracy:'
mean(search$correct_resp,na.rm = TRUE)*100
#Remove NAs
search<-subset(search,search$rt!="NA")
search<-subset(search,search$correct_resp!=0)
#turn variables into factors
search$conjunct<-as.factor(search$conjunct)
search$present<-as.factor(search$present)
#Remove outliers
#search<-subset(search,search$rt<mean(search$rt)+3*sd(search$rt))
#histogram
hist(search$rt,breaks=10)
#Q-Q-plot
qqnorm(search$rt)
#make a log-transformation
search$logrt=log(search$rt)
#histogram
hist(search$logrt,breaks=10)
#Q-Q-plot
qqnorm(search$logrt)
search_model<-lm(logrt~setsize*conjunct*present, data=search)
summary(search_model)
library(ggplot2)
search$setsize_f<-as.factor(search$setsize)
ggplot(search, aes(x = setsize , y = rt, color=conjunct, fill=present)) +
geom_point() + labs(x = "setsize", y = "Response time)") +
geom_smooth(method='lm')
View(search)
sarah<- c(1.95,1.58,1.70,2.46,2.27,2.62,3.32,3.51,3.89,3.41)
mother<-c(3.21,4.04,3.30,3.85,4.13,4.59,4.11,4.29,5.82,5.14)
mean_sarah<-mean(sarah)
mean_mother<-mean(mother)
error_sarah<-sarah-mean_sarah
error_mother<-mother-mean_mother
error_sarah*error_mother
sum_of_scores<- sum(error_sarah*error_mother)
sum_of_scores
cov<-sum_of_scores/9
cov
SD_Sarah<-sqrt(mean_sarah)
cov
Correlation_coefficient<-cov/(0.82*0.79)
Correlation_coefficient
Correlation_coefficient*Correlation_coefficient
roh_squared<-Correlation_coefficient*Correlation_coefficient
Correlation_coefficient_aka_roh<-cov/(0.82*0.79)
install.packages("ggplot2"); install.packages("pastecs"); install.packages ("WRS")
library(ggplot2); library(pastecs); library(WRS)
install.packages ("WRS")
install.packages(“lme4”)
install.packages("lme4")
library(lme4)
politeness= read.csv("http://www.bodowinter.com/tutorial/politeness_data.csv")
View(politeness)
head(politeness)
tail(),
summary(politeness)
, str(),
colnames(politeness)
str(politeness),
colnames(politeness)
str(politeness),
colnames(politeness)
str(politeness)
which(is.na(politeness$frequency))
which(!complete.cases(politeness))
boxplot(frequency ~ attitude*gender,
col=c("white","lightgray"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("white","purple"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("red","purple"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("red","lightpurple"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("red","purple"),politeness)
lmer(frequency ~ attitude, data=politeness)
politeness.model = lmer(frequency ~ attitude + (1|subject) + (1|scenario), data=politeness)
summary(politeness.model)
politeness.model = lmer(frequency ~ attitude + gender + (1|subject) + (1|scenario), data=politeness)
summary(politeness.model)
politeness.null = lmer(frequency ~ gender +
(1|subject) + (1|scenario), data=politeness,
REML=FALSE)
politeness.null = lmer(frequency ~ gender + (1|subject) + (1|scenario), data=politeness,REML=FALSE)
politeness.model = lmer(frequency ~ attitude + gender + (1|subject) + (1|scenario), data=politeness, REML=FALSE)
anova(politeness.null,politeness.model)
coef(politeness.model)
politeness.model = lmer(frequency ~ attitude +
gender + (1+attitude|subject) +
(1+attitude|scenario),
data=politeness,
REML=FALSE)
coef(politeness.model)
politeness.null = lmer(frequency ~ gender + (1+attitude|subject) + (1+attitude|scenario), data=politeness, REML=FALSE)
anova(politeness.null,politeness.model)
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio 4")
library(tidyverse) ; library(stringr) ; library(stringi) ; library(pastecs)
#Now we'll import all of our colelcted datafiles from the reading experiment (30 in total)
#First we look trough our Working Directory and make list of filenames
filenames <- list.files(pattern = "logfile*")
data = data.frame() #create a new empty df for this second part of the portfolio
for (i in filenames) {	#the we loop over the list of files
file = read.csv(i)	#we import the current file
data = rbind(data, file[,])
#and append the 162th line of the current file to our new df 't_test_data'using the rbind function
}
View(data)
#Now we'll import all of our colelcted datafiles from the reading experiment (30 in total)
#First we look trough our Working Directory and make list of filenames
filenames <- list.files(pattern = "logfile*")
data = data.frame() #create a new empty df for this second part of the portfolio
for (i in filenames) {	#the we loop over the list of files
file = read.csv(i)	#we import the current file
data = rbind(data, file[,])
#and append the 162th line of the current file to our new df 't_test_data'using the rbind function
}
View(data)
View(data)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/work/CLasswork/9 - Issa - Mixed Effects model")
library(tidyverse) ; library(stringr) ; library(stringi) ; library(pastecs) ; library(WRS2)
load("stroop_data.Rda")
View(stroop_data)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/work/CLasswork/9 - Issa - Mixed Effects model")
library(tidyverse) ; library(stringr) ; library(stringi) ; library(pastecs) ; library(WRS2)
load("stroop_data.Rda")
library(tidyverse) ; library(lmerTest)
library(tidyverse) ; p_load(lmerTest)
p_load(lmerTest)
install.packages("lmerTest")
library(tidyverse) ; library(lmerTest)
View(stroop_data)
model = lmer(Reaction_Time ~ Emotional + Valence + (1 +ID), stroop_data)
model = lmer(Reaction_time ~ Emotional + Valence + (1 + ID), stroop_data)
model = lmer(Reaction_time ~ Emotional + Valence + (1 + |ID), stroop_data)
model = lmer(Reaction_time ~ Emotional + Valence + (1 + ID), stroop_data)
summary(model)
model = lmer(Reaction_time ~ Emotional + Valence + (1 + Emotional|ID), stroop_data)
summary(model)
model = lmer(Reaction_time ~ Sentiment + (1 + Emotional|ID), stroop_data)
summary(model)
model = lmer(Reaction_time ~ Sentiment + (1 + |ID), stroop_data)
model = lmer(Reaction_time ~ Sentiment + (1 + ID), stroop_data)
summary(model)
model = lmer(Reaction_time ~ Sentiment + (1 + ID), stroop_data)
summary(model)
model = lmer(Reaction_time ~ Sentiment + (1|ID), stroop_data)
summary(model)
model = lmer(Reaction_time ~ Valence + (1|ID), stroop_data)
summary(model)
model = lmer(Reaction_time ~ Emotional + (1|ID), stroop_data)
summary(model)
model = lmer(Reaction_time ~ Emotional + (1 + Emotional|ID), stroop_data)
summary(model)
model = lmer(Reaction_time ~ Emotional, Valence + (1 + Emotional|ID), stroop_data)
summary(model)
model = lmer(Reaction_time ~ Sentiment + (1 + Sentiment|ID), stroop_data)
summary(model)
data = data.frame(res = model$residuals, fit = model$fitted.values)
data = data.frame(res = stroop_data$residuals, fit = stroop_data$fitted.values)
View(data)
data = data.frame(res = model$residuals, fit = model$fitted.values)
ggplot(data, aes(fit, res)) + geom_point() + geom_abline(slope = 0, intercept = 0)
data = data.frame(res = residuals(model), fit = fitted(model))
ggplot(data, aes(fit, res)) + geom_point() + geom_abline(slope = 0, intercept = 0)
model = lmer(Reaction_time ~ Emotional + (1|ID) + (1|Word) + (1|Color) , stroop_data)
summary(model)
data = data.frame(res = residuals(model), fit = fitted(model))
ggplot(data, aes(fit, res)) + geom_point() + geom_abline(slope = 0, intercept = 0)
plot(model)
qqnorm()
qqnorm(model)
qqnorm(residuals(model)
```
qqnorm(residuals(model))
dfbeta(model)
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio 4")
library(tidyverse) ; library(stringr) ; library(stringi) ; library(pastecs)
#Now we'll import all of our colelcted datafiles from the reading experiment (30 in total)
#First we look trough our Working Directory and make list of filenames
filenames <- list.files(pattern = "logfile*")
data = data.frame() #create a new empty df for this second part of the portfolio
for (i in filenames) {	#the we loop over the list of files
file = read.csv(i)	#we import the current file
data = rbind(data, file[,])
#and append the 162th line of the current file to our new df 't_test_data'using the rbind function
}
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio 4")
library(tidyverse) ; library(stringr) ; library(stringi) ; library(pastecs)
#Now we'll import all of our colelcted datafiles from the reading experiment (30 in total)
#First we look trough our Working Directory and make list of filenames
filenames <- list.files(pattern = "logfile*")
data = data.frame() #create a new empty df for this second part of the portfolio
for (i in filenames) {	#the we loop over the list of files
file = read.csv(i)	#we import the current file
data = rbind(data, file[,])
#and append the 162th line of the current file to our new df 't_test_data'using the rbind function
}
Postive_Data <- filter(data, Accurracy == "1")
People_Means <- data %>%
group_by(Full.Name, Condition) %>%
summarise(Mean_Reaction = mean(Reaction.Time), Mean_Accuracy = mean(Accuracy))
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio 4")
library(tidyverse) ; library(stringr) ; library(stringi) ; library(pastecs)
#Now we'll import all of our colelcted datafiles from the reading experiment (30 in total)
#First we look trough our Working Directory and make list of filenames
filenames <- list.files(pattern = "logfile*")
data = data.frame() #create a new empty df for this second part of the portfolio
for (i in filenames) {	#the we loop over the list of files
file = read.csv(i)	#we import the current file
data = rbind(data, file[,])
#and append the 162th line of the current file to our new df 't_test_data'using the rbind function
}
People_Means <- Postive_Data %>%
group_by(Full.Name, Condition) %>%
summarise(Mean_Reaction = mean(Reaction.Time))
Postive_Data <- filter(data, Accurracy == "1")
People_Means <- Postive_Data %>%
group_by(Full.Name, Condition) %>%
summarise(Mean_Reaction = mean(Reaction.Time))
Postive_Data <- filter(data, Accurracy == "1")
View(data)
Postive_Data <- filter(data, Accuracy == "1")
People_Means <- Postive_Data %>%
group_by(Full.Name, Condition) %>%
summarise(Mean_Reaction = mean(Reaction.Time))
View(Postive_Data)
View(People_Means)
Reaction_by_Condition <- aov(Mean_Reaction ~ Condition, data = People_Means)
summary(Reaction_by_Condition)
Reaction_by_Condition <- lm(Mean_Reaction ~ Condition, data = People_Means)
summary(Reaction_by_Condition)
Reaction_by_Condition <- aov(Mean_Reaction ~ Condition, data = People_Means)
summary(Reaction_by_Condition)
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio 4")
library(tidyverse) ; library(stringr) ; library(stringi) ; library(pastecs)
#Now we'll import all of our colelcted datafiles from the reading experiment (30 in total)
#First we look trough our Working Directory and make list of filenames
filenames <- list.files(pattern = "logfile*")
data = data.frame() #create a new empty df for this second part of the portfolio
for (i in filenames) {	#the we loop over the list of files
file = read.csv(i)	#we import the current file
data = rbind(data, file[,])
#and append the 162th line of the current file to our new df 't_test_data'using the rbind function
}
Postive_Data <- filter(data, Accuracy == "1")
People_Means <- Postive_Data %>%
group_by(Full.Name, Condition) %>%
summarise(Mean_Reaction = mean(Reaction.Time))
Reaction_by_Condition <- aov(Mean_Reaction ~ Condition, data = People_Means)
summary(Reaction_by_Condition)
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio 4")
library(tidyverse) ; library(stringr) ; library(stringi) ; library(pastecs)
#Now we'll import all of our colelcted datafiles from the reading experiment (30 in total)
#First we look trough our Working Directory and make list of filenames
filenames <- list.files(pattern = "logfile*")
data = data.frame() #create a new empty df for this second part of the portfolio
for (i in filenames) {	#the we loop over the list of files
file = read.csv(i)	#we import the current file
data = rbind(data, file[,])
#and append the 162th line of the current file to our new df 't_test_data'using the rbind function
}
Postive_Data <- filter(data, Accuracy == "1")
People_Means <- Postive_Data %>%
group_by(Full.Name, Condition) %>%
summarise(Mean_Reaction = mean(Reaction.Time))
Reaction_by_Condition <- aov(Mean_Reaction ~ Condition, data = People_Means)
summary(Reaction_by_Condition)
Reaction_by_Condition_lm <- lm(Mean_Reaction ~ Condition, data = People_Means)
summary(Reaction_by_Condition)
summary(Reaction_by_Condition_lm)
Postive_Data <- filter(data, Accuracy == "1")
People_Means <- Postive_Data %>%
group_by(Full.Name, Condition) %>%
summarise(Mean_Reaction = mean(Reaction.Time))
Reaction_by_Condition <- aov(Mean_Reaction ~ Condition, data = People_Means)
summary(Reaction_by_Condition)
Reaction_by_Condition_lm <- lm(Mean_Reaction ~ Condition, data = People_Means)
summary(Reaction_by_Condition_lm)
Reaction_by_Condition <- aov(Mean_Reaction ~ Condition, data = People_Means)
summary(Reaction_by_Condition)
View(People_Means)
People_Means$Condition <- factor(People_Means$Condition)
Reaction_by_Condition <- aov(Mean_Reaction ~ Condition, data = People_Means)
summary(Reaction_by_Condition)
Reaction_by_Condition_lm <- lm(Mean_Reaction ~ Condition, data = People_Means)
summary(Reaction_by_Condition_lm)
People_Means$Condition <- numeric(People_Means$Condition)
Reaction_by_Condition <- aov(Mean_Reaction ~ Condition, data = People_Means)
summary(Reaction_by_Condition)
People_Means$Condition <- as.numeric(People_Means$Condition)
Reaction_by_Condition <- aov(Mean_Reaction ~ Condition, data = People_Means)
summary(Reaction_by_Condition)
data_mean$Condition <- factor(data_mean$Condition)
People_Means$Condition <- factor(People_Means$Condition)
Reaction_by_Condition <- aov(Mean_Reaction ~ Condition, data = People_Means)
summary(Reaction_by_Condition)
Reaction_by_Condition_lm <- lm(Mean_Reaction ~ Condition, data = People_Means)
summary(Reaction_by_Condition_lm)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio 4")
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio 4")
library(car)
library(compute.es)
library(ggplot2)
library(multcomp)
library(pastecs)
library(WRS2)
library(stringi)
library(stringr)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio 4")
library(car)
library(compute.es)
library(ggplot2)
library(multcomp)
library(pastecs)
library(WRS2)
library(stringi)
library(stringr)
library(tidyverse)
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio 4")
library(car)
library(compute.es)
library(ggplot2)
library(multcomp)
library(pastecs)
library(WRS2)
library(stringi)
library(stringr)
library(tidyverse)
# create list with filenames starting with 'log' from the working directory
filenames <- list.files(pattern = "log*")
# create loop
data = data.frame() # create empty dataframe to put "things" from loop into it
# create loop
for (i in filenames){ # tells r to loop all the filenames (the list we created with the filenames)
file = read.csv(i) # we need to import the data into r, give us access to the dataframes, file is the current data we are working on --> everytime we go through the loop it changes
data = rbind(data, file[,]) # the comma tells r to take row number 162 and all the columns
}
data_correct <- filter(data, Accuracy == 1)
# calculate the mean for each participant
data_mean <- data_correct %>%
group_by(Full.Name, Condition) %>%
summarise(mean_reaction = mean(Reaction.Time))
# use factor() to tell R to treat the Condition column as a categorical factor
data_mean$Condition <- factor(data_mean$Condition)
line_graph <- ggplot(data_mean, aes(Condition, mean_reaction)) # define plot
line_graph + stat_summary(fun.y = mean, geom = "point") + # create point for mean in each group
stat_summary(fun.y = mean, geom = "line", aes(group = 1), color = "Blue", linetype = "dashed") + # create lines between each mean, set group = 1 because we are joining summary points instead of individual points
stat_summary(fun.data = mean_cl_boot, geom = "errorbar", width = 0.2) + # create confidence intervals based on bootstrapping, since we don't assume normality
labs(x = "Conditions", y = "Mean reaction time of judging a syllogism")
# use by() to get descriptive statistics for each condition
by(data_mean$mean_reaction, data_mean$Condition, stat.desc)
# residual plot, to check linearity in the residuals + variance is different at different ends of the predictor
model <- lm(mean_reaction~Condition, data = data_mean)
data = data.frame(res = residuals(model), fit = fitted(model))
ggplot(data, aes(fit, res)) + geom_point() + geom_abline(slope = 0, intercept = 0)
plot(fitted(model), residuals(model))
summary(model)
# residual plot, to check linearity in the residuals + variance is different at different ends of the predictor
model <- lm(mean_reaction~Condition, data = data_mean)
data = data.frame(res = residuals(model), fit = fitted(model))
ggplot(data, aes(fit, res)) + geom_point() + geom_abline(slope = 0, intercept = 0)
plot(fitted(model), residuals(model))
summary(model)
# normality of residuals
qqnorm(residuals(model))
# levene's test
leveneTest(data_mean$mean_reaction, data_mean$Condition, center = median)
# annova model
model1 <- aov(mean_reaction~Condition, data = data_mean)
summary(model1)
# lm() model
model2 <- lm(mean_reaction~Condition, data = data_mean)
summary(model2)
View(data_mean)
WideData <- unstack(data_mean, mean_reaction ~ Condition)
View(data_mean)
Widedata <- filter(data_mean, Condition, mean_reaction)
View(Widedata)
Widedata <- data_mean [,c("Condition","mean_reaction")]
View(Widedata)
WideData <- unstack(data_mean, mean_reaction ~ Condition)
WideData <- unstack(Widedata, mean_reaction ~ Condition)
View(Widedata)
Widedata <- unstack(Widedata, mean_reaction ~ Condition)
Widedata <- data_mean [,c("Condition","mean_reaction")]
unstack(Widedata, mean_reaction ~ Condition)
View(Widedata)
WideData <- unstack(data_mean, mean_reaction ~ Condition)
t1way(WideData, tr = .2, grp = c(1,2,3))
t1way(WideData, tr = .2, grp = c(x,y,z))
t1way(WideData)
t1way(mean_data)
t1waybt(WideData)
t1waybt(mean_data)
unstack <- unstack(data_mean, values~ind)
WideData <- stack(data_mean, mean_reaction ~ Condition)
