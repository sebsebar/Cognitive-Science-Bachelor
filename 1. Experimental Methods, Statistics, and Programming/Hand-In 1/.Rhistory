metallica<-c("Lars","James","Jason","Kirk")
metalica
print(metallica)
metallica<-metallica[metallica!= "Jason"]
metallica
metallica<-c(metallica, "Rob")
metallica
friends<-c(friends, "Mille", "Nina", "Kiri", "Jacob")
friends<-c("Mille","Nina","Kiri","Jacob")
friends
friends<-c("Mille","Nina","Kiri","Jacob")
friends<-friends[]
friends<-friends[!= "Jacob"]
friends<-friends[friends!= "Jacob"]
friends
friends<-c(friends, "Jacob")
friends
metallica
metallica
friends
friends<-friends[friends != "Jacob]
"]
friends
friends<-friends[friends != "Jacob"]
friends
friends<-friends[friends!= "Jacob"]
friends
friends<-c(friends, "Jacob")
friends
metallicaNames<-c("Lars","James","Kirk","Rob")
metallicaNames
metallicaAges<-c(47, 47, 48, 46)
metallicaAges
metallica<-data.frame(Name = metallicaNames, Age = metallicaAges)
metallica
metallica$Name
metallica$Age
metallica$childAge<-c(12, 12, 4, 6)
metallica$childAge
metallica
names(metallica)
metallica$fatherhoodAge<- metallica$Age & minus metallica$childAge
metallica$fatherhoodAge<- metallica$Age & - metallica$childAge
fatherhoodAge
metallica
metallica$fatherhoodAge<- metallica$Age - metallica$childAge
metallica
metallicaNames<-c("Lars","James","Kirk","Rob")
metallicaNames
metallicaAges<-c(47, 47, 48, 46)
metallicaAges
metallica<-data.frame(Name = metallicaNames, Age = metallicaAges)
metallica$Age
metallica$childAge<-c(12, 12, 4, 6)
metallica$childAge
metallica
names(metallica)
metallica$fatherhoodAge<- metallica$Age - metallica$childAge
name<-c("Ben", "Martin", "Andy", "Paul", "Graham", "Carina", "Karina", "Doug", "Mark", "Zoe")
husband<-as.Date(c("1973-06-21", "1970-07-16", "1949-10-08", "1969-05-24"))
wife<-as.Date(c("1984-11-12", "1973-08-02", "1948-11-11", "1983-07-23"))
agegap<-husband-wife
agegap
birth_date<-as.Date(c("1977-07-03", "1969-05-24", "1973-06-21","1970-07-16", "1949-10-10", "1983-11-05", "1987-10-08", "1989-09-16","1973-05-20", "1984-11-12"))
job<-c(1,1,1,1,1,2,2,2,2,2)
job
job<-factor(job, levels = c(1:2), labels = c("Lecturer", "Student"))
job<-gl(2, 5, labels = c("Lecturer", "Student"))
levels(job)
levels(job)<-c("Medical Lecturer", "Medical Student")
friends<-c(5,2,0,4,1,10,12,15,12,17)
alcohol<-c(10,15,20,5,30,25,20,16,17,18)
income<-c(20000,40000,35000,22000,50000,5000,100,3000,10000,10)
neurotic<-c(10,17,14,13,21,7,13,9,14,13)
lecturerData<-data.frame(name,birth_date,job,friends,alcohol,income,neurotic)
lecturerData
lecturerPersonality <- lecturerData[, c("friends", "alcohol","neurotic")]
lecturerPersonality
lecturerOnly <- lecturerData[job=="Medical Lecturer",]
lecturerOnly
alcoholPersonality <- lecturerData[alcohol > 10, c("friends","alcohol", "neurotic")]
alcoholPersonality
alcoholPersonalityMatrix <- as.matrix(alcoholPersonality)
alcoholPersonalityMatrix
alcoholPersonalityMatrix <- as.matrix(lecturerData[alcohol > 10,c("friends", "alcohol", "neurotic")])
alcoholPersonalityMatrix
satisfactionData = read.delim("Honeymoon Period.dat", header = TRUE)
satisfactionData = read.delim("Honeymoon Period.dat", header = TRUE)
satisfactionData = read.delim("Honeymoon Period.dat.txt", header = TRUE)
setwd("~/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio")
#Load data
search<- read.csv("~/Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
#Load data
search<- read.csv("~Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
#Load data
search<- read.csv("Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
#Load data
search<- read.csv("/Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
'% accuracy:'
mean(search$correct_resp,na.rm = TRUE)*100
#Load data
search<- read.csv("/Users/FlowersnIce-cream/Downloads/0/03_visual_search_stuff/visual_search_data/Sebber (2017-09-20 14-30-47).csv", sep=";")
'% accuracy:'
mean(search$correct_resp,na.rm = TRUE)*100
#Remove NAs
search<-subset(search,search$rt!="NA")
search<-subset(search,search$correct_resp!=0)
#turn variables into factors
search$conjunct<-as.factor(search$conjunct)
search$present<-as.factor(search$present)
#Remove outliers
#search<-subset(search,search$rt<mean(search$rt)+3*sd(search$rt))
#histogram
hist(search$rt,breaks=10)
#Q-Q-plot
qqnorm(search$rt)
#make a log-transformation
search$logrt=log(search$rt)
#histogram
hist(search$logrt,breaks=10)
#Q-Q-plot
qqnorm(search$logrt)
search_model<-lm(logrt~setsize*conjunct*present, data=search)
summary(search_model)
library(ggplot2)
search$setsize_f<-as.factor(search$setsize)
ggplot(search, aes(x = setsize , y = rt, color=conjunct, fill=present)) +
geom_point() + labs(x = "setsize", y = "Response time)") +
geom_smooth(method='lm')
View(search)
sarah<- c(1.95,1.58,1.70,2.46,2.27,2.62,3.32,3.51,3.89,3.41)
mother<-c(3.21,4.04,3.30,3.85,4.13,4.59,4.11,4.29,5.82,5.14)
mean_sarah<-mean(sarah)
mean_mother<-mean(mother)
error_sarah<-sarah-mean_sarah
error_mother<-mother-mean_mother
error_sarah*error_mother
sum_of_scores<- sum(error_sarah*error_mother)
sum_of_scores
cov<-sum_of_scores/9
cov
SD_Sarah<-sqrt(mean_sarah)
cov
Correlation_coefficient<-cov/(0.82*0.79)
Correlation_coefficient
Correlation_coefficient*Correlation_coefficient
roh_squared<-Correlation_coefficient*Correlation_coefficient
Correlation_coefficient_aka_roh<-cov/(0.82*0.79)
install.packages("ggplot2"); install.packages("pastecs"); install.packages ("WRS")
library(ggplot2); library(pastecs); library(WRS)
install.packages ("WRS")
install.packages(“lme4”)
install.packages("lme4")
library(lme4)
politeness= read.csv("http://www.bodowinter.com/tutorial/politeness_data.csv")
View(politeness)
head(politeness)
tail(),
summary(politeness)
, str(),
colnames(politeness)
str(politeness),
colnames(politeness)
str(politeness),
colnames(politeness)
str(politeness)
which(is.na(politeness$frequency))
which(!complete.cases(politeness))
boxplot(frequency ~ attitude*gender,
col=c("white","lightgray"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("white","purple"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("red","purple"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("red","lightpurple"),politeness)
boxplot(frequency ~ attitude*gender,
col=c("red","purple"),politeness)
lmer(frequency ~ attitude, data=politeness)
politeness.model = lmer(frequency ~ attitude + (1|subject) + (1|scenario), data=politeness)
summary(politeness.model)
politeness.model = lmer(frequency ~ attitude + gender + (1|subject) + (1|scenario), data=politeness)
summary(politeness.model)
politeness.null = lmer(frequency ~ gender +
(1|subject) + (1|scenario), data=politeness,
REML=FALSE)
politeness.null = lmer(frequency ~ gender + (1|subject) + (1|scenario), data=politeness,REML=FALSE)
politeness.model = lmer(frequency ~ attitude + gender + (1|subject) + (1|scenario), data=politeness, REML=FALSE)
anova(politeness.null,politeness.model)
coef(politeness.model)
politeness.model = lmer(frequency ~ attitude +
gender + (1+attitude|subject) +
(1+attitude|scenario),
data=politeness,
REML=FALSE)
coef(politeness.model)
politeness.null = lmer(frequency ~ gender + (1+attitude|subject) + (1+attitude|scenario), data=politeness, REML=FALSE)
anova(politeness.null,politeness.model)
knitr::opts_chunk$set(echo = TRUE)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/portfolio 5")
library(lmerTest) ; library(boot) ; library(caret) ; library(mlogit) ; library(MuMIn) ; library(car) ; library(Rcmdr)
load("kikibobo.Rda")
# notice that echo = FALSE which means that this part of the analysis will not be visible in the report
###############################################
# This section creates a function called      #
# logisticPseudoR2s().  To use it             #
# type logisticPseudoR2s(myLogisticModel)     #
###############################################
logisticPseudoR2s <- function(LogModel) {
dev <- LogModel$deviance
nullDev <- LogModel$null.deviance
modelN <-  length(LogModel$fitted.values)
R.l <-  1 -  dev / nullDev
R.cs <- 1- exp ( -(nullDev - dev) / modelN)
R.n <- R.cs / ( 1 - ( exp (-(nullDev / modelN))))
cat("Pseudo R^2 for logistic regression\n")
cat("Hosmer and Lemeshow R^2  ", round(R.l, 3), "\n")
cat("Cox and Snell R^2        ", round(R.cs, 3), "\n")
cat("Nagelkerke R^2           ", round(R.n, 3),    "\n")}
# Here we get an insight into which type of figures we have the most of - in terms of size and shape - which will determine the baseline for R - The bigger amount will be set as baseline. That means that we´ll make predictions about how much more likely it is get big shapes compared to small and curved shapes compared to jagged - unless we relevel.
table(kikibobo$size)
"
big  sma
1917 2003
"
table(kikibobo$shape)
"
curved jagged
1822   2098
"
# Eventhough our hypothesis is that the vowel has an effect on the size, and vice versa, it might be interestring to see if consonants have an effect on size as well, so we include it as a predictor. Furthermore we´ll include (1|ID) as a random intercepts, beacuse we have a repeated measures design and people might differ in baseline.
model1 = glmer(size ~ vowel + (1|id), data = kikibobo, family = "binomial")
summary(model1)
"
Fixed effects:
Estimate Std. Error z value Pr(>|z|)
(Intercept) -0.23894    0.05638  -4.238 2.25e-05 ***
vowelO       0.59059    0.06463   9.137  < 2e-16 ***
consonantK  -0.02296    0.06462  -0.355    0.722
"
# The vocal O
#Odds
exp(-0.23894+0.59059)
# odds are 1.421411
# Odds are above 1 - so we can expect that there is a higher probability of choosing a big model with vowel O
# The exact Probabilities
inv.logit(-0.23894+0.59059)
# the probabilities are 59% of choosing a big model when the vowel is an O
# The consonant K
#odds
exp(-0.23894+-0.02296)
# odds are 0.769588
#Probabilities
inv.logit(-0.23894+-0.02296)
# the probabilities are 44% of choosing a Big model when the consonant is an K
# But this probability is not significant
model2 <- glmer(shape ~ consonant + (1|id), data = kikibobo, family = "binomial")
summary(model2)
"
Fixed effects:
Estimate Std. Error z value Pr(>|z|)
(Intercept)  0.57011    0.05829   9.780   <2e-16 ***
consonantK  -1.42233    0.06907 -20.592   <2e-16 ***
vowelO       0.60614    0.06899   8.786   <2e-16 ***
"
# The vocal O
#Odds
exp(0.57011+0.60614)
# odds are 3.242193
#Probabilities
inv.logit(0.57011+0.60614)
# the probabilities are 76% of choosing a curved model when the vowel is an O
# The consonant K
#odds
exp(0.57011-1.42233)
# odds are 0.4264671
#Probabilities
inv.logit(0.57011-1.42233)
# the probabilities are 30% of choosing a curved model when the consonant is an K
logisticPseudoR2s(model2)
# Here we get an insight into which type of figures we have the most of - in terms of size and shape - which will determine the baseline for R - The bigger amount will be set as baseline. That means that we´ll make predictions about how much more likely it is get big shapes compared to small and curved shapes compared to jagged - unless we relevel.
table(kikibobo$size)
"
big  sma
1917 2003
"
table(kikibobo$shape)
"
curved jagged
1822   2098
"
# Eventhough our hypothesis is that the vowel has an effect on the size, and vice versa, it might be interestring to see if consonants have an effect on size as well, so we include it as a predictor. Furthermore we´ll include (1|ID) as a random intercepts, beacuse we have a repeated measures design and people might differ in baseline.
model1 = glm(size ~ vowel + (1|id), data = kikibobo, family = "binomial")
model1Chi <- model1$null.deviance - model1$deviance
model1 = glmer(size ~ vowel + (1|id), data = kikibobo, family = "binomial")
model1 = glmer(size ~ vowel + (1|id), data = kikibobo, family = "binomial")
summary(model1)
exp(-0.25041+0.59057)
inv.logit(-0.25041+0.59057)
model2 <- glmer(shape ~ consonant + (1|id), data = kikibobo, family = "binomial")
model2 <- glmer(shape ~ consonant + (1|id), data = kikibobo, family = "binomial")
summary(model2)
View(kikibobo)
model1.2 = glmer(size ~ consonant + (1|id), data = kikibobo, family = "binomial")
summary(model1.2)
model2 <- glmer(shape ~ consonant + (1|id), data = kikibobo, family = "binomial")
model2 <- glmer(shape ~ consonant + (1|id), data = kikibobo, family = "binomial")
summary(model2)
View(kikibobo)
model2.2 <- glmer(shape ~ vowel + (1|id), data = kikibobo, family = "binomial")
model2.2 <- glmer(shape ~ vowel + (1|id), data = kikibobo, family = "binomial")
summary(model2.2)
exp(0.85460-1.39163)
inv.logit(0.85460-1.39163)
exp(-0.12465+0.53650)
inv.logit(-0.12465+0.53650)
kikibobo$size <- relevel(kikibobo$size, "sma")
model1 = glmer(size ~ vowel + (1|id), data = kikibobo, family = "binomial")
model1 = glmer(size ~ vowel + (1|id), data = kikibobo, family = "binomial")
summary(model1)
?relevel
View(kikibobo)
kikibobo$size <- relevel(kikibobo$size, "sma")
kikibobo$shape <- relevel(kikibobo$shape, "jagged")
model1 = glmer(size ~ vowel + (1|id), data = kikibobo, family = "binomial")
summary(model1)
0.25041-0.59057
inv.logit(0.25041-0.59057)
model1.2 = glmer(size ~ consonant + (1|id), data = kikibobo, family = "binomial")
summary(model1.2)
model2 <- glmer(shape ~ consonant + (1|id), data = kikibobo, family = "binomial")
summary(model2)
exp(-0.85460+1.39163)
inv.logit(-0.85460+1.39163)
model2.2 <- glmer(shape ~ vowel + (1|id), data = kikibobo, family = "binomial")
summary(model2.2)
exp(0.12465-0.53650)
inv.logit(0.12465-0.53650)
knit_with_parameters('~/Google Drev/Hogwarts/R Studio/portfolios/portfolio 5/Portfolio5.Rmd', encoding = 'UTF-8')
View(kikibobo)
Faster_Hands <- personality_data %>%
# We start by creating a new object called Faster_Hands -> then we designate it's variables by first entering the 'personality_data'
group_by(handedness) %>%
# and then selecting and grouping all the entries in the handedness variable, which will enable  us to
summarise(tongue_twister = mean(tongue_twister),count = n())
library(tidyverse)
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/Portfolio")
load("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/Portfolio/2_clean_cogsci_data.Rda")
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio")
load("2_clean_cogsci_data.Rda")
Faster_Hands <- personality_data %>%
# We start by creating a new object called Faster_Hands -> then we designate it's variables by first entering the 'personality_data'
group_by(handedness) %>%
# and then selecting and grouping all the entries in the handedness variable, which will enable  us to
summarise(tongue_twister = mean(tongue_twister),count = n())
ggplot(personality_data, aes(x = handedness, y = tongue_twister, fill=handedness)) + geom_bar(stat = "summary", fun.y = mean) + geom_errorbar(stat = "summary", fun.data = mean_cl_boot, width = 0.2)
View(Faster_Hands)
BoomBoom_People <- personality_data %>%
# We start by creating a new object called BoomBoom_People -> then we designate it's variables by first entering the 'personality_data'
group_by(gender) %>%
# and then selecting and grouping all the entries in the gender variable, which will enable  us to
summarise(volume = mean(volume), count = n())
View(BoomBoom_People)
Oc_Dom_SnurreSnub_DonaldDuck <- personality_data %>%
# We start by creating a new object called Oc_Dom_SnurreSnub_DonaldDuck -> then we designate it's variables by first entering the 'personality_data'
group_by(ocular_dominance, duck_rabbit) %>%
# and then selecting and grouping all the entries in the ocular_dominance and duck_rabbit variable, which will enable  us to
summarise(count= n())
View(Oc_Dom_SnurreSnub_DonaldDuck)
HeadbangingByNationality <- personality_data %>%
# We start by creating a new object called HeadbangingByNationality -> then we designate it's variables by first entering the 'personality_data'
group_by(native_speaker_DK) %>%
# and then selecting and grouping all the entries in the native_speaker variable, which will enable  us to
summarise(Mean_music = mean(hours_music), Standard_Deviation = sd(hours_music), count = n())
View(HeadbangingByNationality)
MusicManiacs_ToDegreeOf_FloorSweeping <- music_days %>%
#Now we enter our new mutated dataset
group_by(yes_no) %>%
#Group our data by the yes_no variable we just created
summarise(Daily_Music_Minutes = mean(music_pr_day), Vol = mean(volume), count = n())
music_days <- mutate(personality_data, music_pr_day = hours_music/7*60, yes_no = ifelse(touch_floor %in% c("Yes of course", "Yes"),"Yes", "No"))
MusicManiacs_ToDegreeOf_FloorSweeping <- music_days %>%
#Now we enter our new mutated dataset
group_by(yes_no) %>%
#Group our data by the yes_no variable we just created
summarise(Daily_Music_Minutes = mean(music_pr_day), Vol = mean(volume), count = n())
View(MusicManiacs_ToDegreeOf_FloorSweeping)
Faster_Hands <- personality_data %>%
# We start by creating a new object called Faster_Hands -> then we designate it's variables by first entering the 'personality_data'
group_by(handedness) %>%
# and then selecting and grouping all the entries in the handedness variable, which will enable  us to
summarise(tongue_twister = mean(tongue_twister),count = n())
ggplot(personality_data, aes(x = handedness, y = tongue_twister, fill=handedness)) + geom_bar(stat = "summary", fun.y = mean) + geom_errorbar(stat = "summary", fun.data = mean_cl_boot, width = 0.2)
View(personality_data)
faster_hands <- personality_data %>%
group_by(handedness) %>%
summarise(tongue_twister = mean(tongue_twister),count = n())
opts_knit$set(root.dir = "/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio")
library(tidyverse)
# We use the library function to Load the tidyverse package that have previously been installed from the online CRAN database. This allows us to use the GGPLOT2 functions
setwd("/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio")
# We set the working directory (WD for short) to the folder that contains our dataset
opts_knit$set(root.dir = "/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio")
load("2_clean_cogsci_data.Rda")
# Now we use the load function to get our RDA file with data about the classes personalities into RStudio.
knitr::opts_chunk$set(echo = TRUE)
opts_knit$set(root.dir = "/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio")
knitr::opts_chunk$set(echo = TRUE)
opts_chunk$set(root.dir = "/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "/Users/FlowersnIce-cream/Google Drev/Hogwarts/R Studio/portfolios/Portfolio")
